机器学习---
从数据集中自动分析出模型，依据模型处理问题（做出预测）
数据集--+
特征值-+-
原始数据的结构化展示
目标值-+-
预测的数据

机器学习算法分类---
监督学习--+
目标值为离散型数据-+-
分类问题
算法：k-近邻算法，贝叶斯分类，决策树与随机森林，逻辑回归
目标值为连续型数据-+-
回归问题
算法：线性回归，岭回归
无监督学习--+
目标值为无-+-
算法：聚类，k-means

机器学习的开发流程---
1）获取数据
2）数据处理
3）特征工程
4）算法训练--模型
5）模型评估
6）应用

常用数据集---
--+sklearn
--+kaggle
--+UCI

-+-sklearn
获取数据集sklearn.datesets
load_*() 	获取大的数据集
fetch_*() 	获取大的数据集


获取数据的返回值-++
datesets.base.Bunch(继承自字典) 

数据集的划分-+-
训练模型-++
训练集特征值 x_train
训练集目标值 y_train
测试模型-++
测试集特征值 x_test
测试集目标值 y_test
划分函数-++
sklearn.model_selection.train_test_split(arrays,*options)
x 数据集的特征值
y 数据集的标签值
test_size测试集的大小
random_state 随机数种子

特征工程---
特征抽取--+
sklearn.feature_extraction
字典抽取-+-
feature_extraction.DictVectorizer(sparse=)
文本抽取
特征：单词，句子，短语，字母
feature_extraction.text -++
text.CountVectorizer(stop_word=[]) +--
统计样本特征词出现个数 
统计中文分词调用jieba库
text.TfidefVectorizer(stop_word=[])  +--
关键词统计
Tf-idef 	term frequency - inverse document frequency
tf-idef 	重要程度

特征以预处理--+
无量纲化-+-
使不同规格的数据转换到统一规格
规范化-+-
受到异常点影响大
x'=(x-min)/(max-min)
x"=x'*(mx-mi)+mi 		放缩区间(mi,mx)默认（1，0）
sklearn.preprocessing.MinMaxScaler(feature_range=(1,0)....)
标准化-+-
通过对原始数据进行变换到均值为0，标准差为1范围内
x'= x-avg/p	作用于每一列，avg使平均值 p使标准差
sklearn.preproecessing.StandardScaler()

特征降维--+
降维是指在某些特定条件下，降低特征个数，得到一组不相关的主要变量的过程
特征选择-+-
数据中包含冗余或相关变量，旨在从原有的特征中找到主要特征
filter 过滤式-++
方差选择法 : 过滤低方差数据
sklearn.feature.selection.VarianceThreshold(threshold = 0)

相关系数法
Embedded嵌入式-++
决策树
正则化
深度学习

主成分分析-+-


